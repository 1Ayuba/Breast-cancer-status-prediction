---
title: "Breast Cancer Prediction"
author: "Ayuba Ahmed Bayugo"
date: "1/14/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
INTRODUCTION: Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.
n the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: "Robust Linear Programming Discrimination of Two Linearly Inseparable Sets", Optimization Methods and Software 1, 1992, 23-34].
This database is also available through the UW CS ftp server:
ftp ftp.cs.wisc.edu
cd math-prog/cpo-dataset/machine-learn/WDBC/
Also can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29
Attribute Information:
1) ID number
2) Diagnosis (M = malignant, B = benign)
3-32)
Ten real-valued features are computed for each cell nucleus:
a) radius (mean of distances from center to points on the perimeter)
b) texture (standard deviation of gray-scale values)
c) perimeter
d) area
e) smoothness (local variation in radius lengths)
f) compactness (perimeter^2 / area - 1.0)
g) concavity (severity of concave portions of the contour)
h) concave points (number of concave portions of the contour)
i) symmetry
j) fractal dimension ("coastline approximation" - 1)

GOAL: we will explore how we can predict the status of breast cancer using predictive modeling

```{r}
bcd <- read.csv("data.csv", stringsAsFactors = FALSE)
#print(bcd)
```

view the top few rows (in this case 4) of the dataset. 
```{r}
head(bcd)
```

since we will not be needing the ID column, let's drop it
```{r}
bcd <- bcd[-1 ]
```

For our predicted variables, we set the B and M as factors with labels as Benign and Malignant

```{r}
bcd$diagnosis <- factor(bcd$diagnosis, levels = c("B","M"), labels = c("Benign", "Malignant"))
```
Since KNN is a distance-based algorithm, it is a good idea to scale all our numeric features. That way a few features wonâ€™t dominate in the distance calculations. We first
create a function and then apply that function to all our features (column 2 to 31).

```{r}
normalize<-function(x)
{
  return((x-min(x))/max(x)-min(x))
}
bcd_n<-as.data.frame(lapply(bcd[,2:31], normalize))
```

To implement KNN, we need to install a package called class.To check the performance of the model, our data is divided into training and test set. We train the model on the training set and validate the test set.
```{r}
install.packages("class")
library("class")
```


```{r}
bcd_train<-bcd_n[1:469,]

dim(bcd_train)

bcd_test<-bcd_n[470:569,]
dim(bcd_test)
bcd_train_label <- bcd[1:469,1]
bcd_test_label <- bcd[470:569,1]
```
